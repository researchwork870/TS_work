{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cfa63cc",
   "metadata": {},
   "source": [
    "# NON-LINEAR ML TECHNIQUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4bf9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd \n",
    "import math\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.transformations.series.detrend import Deseasonalizer, Detrender\n",
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.utils.plotting import plot_series\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster,ReducedForecaster\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import xgboost as xg\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to use this notebook for univarate time series analysis :-\n",
    "# 1) The primary requirement is not to have missing values or categorial(string) data for time_dependent variable \n",
    "#    and time_column.\n",
    "# 2) This cell requires information on file_name (only csv), time_dependent_variable, time_column, date_time format (frmt)\n",
    "#    and resample grain(X). After filling the required information correctly, you can run all the cells (Cell ---> Run All)\n",
    "# 3) Example :-\n",
    "#   file_name               = \"JetRail Avg Hourly Traffic Data - 2012-2013.csv\"\n",
    "#   time_dependent_variable = \"Count\"    (column name in your dataset)\n",
    "#   time_column             = \"Datetime\" (column name in your dataset)\n",
    "#   frmt                    = \"%Y-%m-%d\"\n",
    "#   X                       = \"D\" \n",
    "\n",
    "file_name = \"Monthly Production of Chocolate - Australia.csv\"\n",
    "time_dependent_variable = \"Volume\"\n",
    "time_column = \"Month\"\n",
    "frmt =  '%Y-%m'\n",
    "X = \"M\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090a572c",
   "metadata": {},
   "source": [
    "### Reading the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa96c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(time_column, file_name, frmt='%Y-%m-%d %H:%M:%S', X= \"D\"):\n",
    "    df = pd.read_csv(file_name, parse_dates= True)\n",
    "    df = df[[time_column,time_dependent_variable]]\n",
    "    df[time_column] = pd.to_datetime(df[time_column],format=frmt) \n",
    "    df.index = df[time_column]\n",
    "    df = df.resample(X).mean()\n",
    "    df.reset_index(inplace= True)\n",
    "    return df\n",
    "df = data(time_column, file_name, frmt, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7bc9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ac112",
   "metadata": {},
   "source": [
    "## Defining the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c5562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
    "    def mean_absolute_percentage_error(y_true, y_pred):\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print('Evaluation metric results:-')\n",
    "    print(f'MSE is : {metrics.mean_squared_error(y_true, y_pred)}')\n",
    "    print(f'MAE is : {metrics.mean_absolute_error(y_true, y_pred)}')\n",
    "    print(f'RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}')\n",
    "    print(f'MAPE is : {mean_absolute_percentage_error(y_true,y_pred)}')\n",
    "    print(f'R2 is : {metrics.r2_score(y_true, y_pred)}',end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3612fee7",
   "metadata": {},
   "source": [
    "## Plot Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ffe68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot():\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(train.index, train[time_dependent_variable], label='Train')\n",
    "    plt.plot(test.index,test[time_dependent_variable], label='Test')\n",
    "    plt.plot(test.index,y_pred, label= 'forecast')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('forecast')\n",
    "    plt.show()\n",
    "    timeseries_evaluation_metrics_func(test[time_dependent_variable],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ce57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ml():\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(train.index, train[time_dependent_variable], label='Train')\n",
    "    plt.plot(test.index,test[time_dependent_variable], label='Test')\n",
    "    plt.plot(test.index,pred, label= 'forecast')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('forecast')\n",
    "    plt.show()\n",
    "    timeseries_evaluation_metrics_func(test_Y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9675b67",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "To use supervised machine learning, we need input and output variables. We can create features from a univariate time series in the following ways :-\n",
    "- Date Time Features : These are components of the time step itself for each observation.\n",
    "- Lag Features : These are values at prior time steps.\n",
    "- Window Features : These are a summary of values over a fixed window of prior time steps.\n",
    "\n",
    "let's try and explore each one of them...\n",
    "\n",
    "#### 1) Date Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5a1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_features(df):\n",
    "    df['year'] = df[time_column].dt.year\n",
    "    df['quarter'] = df[time_column].dt.quarter\n",
    "    df['month'] = df[time_column].dt.month\n",
    "    df['week_day'] = df[time_column].dt.weekday\n",
    "    return df\n",
    "df_date_features = date_features(df)[[\"year\",\"quarter\",\"month\",\"week_day\",time_dependent_variable]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2db171",
   "metadata": {},
   "source": [
    "#### 2) Lag Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e4aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lag_features = pd.DataFrame()\n",
    "\n",
    "def lag_features(n):\n",
    "    df_lag_features[\"lag_{}\".format(n)] = df[time_dependent_variable].shift(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bcca37",
   "metadata": {},
   "source": [
    "Let's take lag = 1 and lag = 2 as features. It totally depends on your problem......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want a different lag k just write lag_features(k) and the function would automatically do it for you..\n",
    "lag_features(1)\n",
    "lag_features(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a3cb8a",
   "metadata": {},
   "source": [
    "#### 3) Window Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8abc8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_window_features = pd.DataFrame()\n",
    "\n",
    "def rolling_mean(n):\n",
    "    df_window_features[\"Rolling_mean_{}\".format(n)] = df[time_dependent_variable].shift(1).rolling(window = n).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c8a0f",
   "metadata": {},
   "source": [
    "Let's take rolling mean of 2 and 5. It totally depends on your problem....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f45fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want a different rolling mean k just write rolling_mean(k) and the function would automatically do it for you..\n",
    "rolling_mean(2)\n",
    "rolling_mean(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc9e939",
   "metadata": {},
   "source": [
    "#### Combining the table with features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f37ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(pd.merge(df_date_features,df_lag_features,left_index=True,right_index=True),df_window_features,left_index=True, right_index=True)\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec633a52",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test using (you can use any one of them) :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca26f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This splits the data into train and test using default split_size = 0.7\n",
    "def train_test_split_perc(df, split= 0.7):\n",
    "    total_size=len(df)\n",
    "    train_size=math.floor(split*total_size) #(70% Dataset)\n",
    "    train = df.head(train_size)\n",
    "    test  = df.tail(len(df) - train_size)\n",
    "    return train,test\n",
    "    \n",
    "train,test = train_test_split_perc(df, split= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = train[time_dependent_variable]\n",
    "train_X = train[[i for i in df.columns if i != time_dependent_variable]]\n",
    "test_Y = test[time_dependent_variable]\n",
    "test_X = test[[i for i in df.columns if i != time_dependent_variable]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_Y) == len(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78329577",
   "metadata": {},
   "source": [
    "### Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf5e500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(algorithm):\n",
    "    forecaster = TransformedTargetForecaster([(\"deseasonalise\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
    "                                          (\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=2))),\n",
    "                                          (\"forecast\",make_reduction(algorithm.fit(train_X, train_Y), window_length=5, strategy=\"recursive\"))])\n",
    "    fh = ForecastingHorizon(test.index, is_relative=False)\n",
    "    forecaster.fit(train[time_dependent_variable])\n",
    "    y_pred = forecaster.predict(fh)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(train.index, train[time_dependent_variable], label='Train')\n",
    "    plt.plot(test.index,test[time_dependent_variable], label='Test')\n",
    "    plt.plot(test.index,y_pred, label= 'forecast')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('forecast')\n",
    "    plt.show()\n",
    "    timeseries_evaluation_metrics_func(test[time_dependent_variable],y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7510866b",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b0130",
   "metadata": {},
   "source": [
    "### 1) LightGBM (univariate)\n",
    "##### Pipelining, detrending and deseasonalization<a class=\"anchor\" id=\"section_3_2\"></a>\n",
    "\n",
    "A common composition motive is pipelining: for example, first deseasonalizing or detrending the data, then forecasting the\n",
    "detrended/deseasonalized series. When forecasting, one needs to add the trend and seasonal component back to the data. \n",
    "\n",
    "Create Pipeline :-\n",
    "- Separate the Seasonal Component.\n",
    "- Fit a forecaster for the trend.\n",
    "- Fit a Autoregressor to the resdiual(autoregressing on four historic values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf2194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_target_forecaster(alpha,params):\n",
    "    \n",
    "    #Initialize Light GBM Regressor \n",
    "    \n",
    "    regressor = lgb.LGBMRegressor(alpha = alpha,**params)\n",
    "    \n",
    "    forecaster = TransformedTargetForecaster([(\"deseasonalise\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
    "                                              (\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=2))),\n",
    "                                            (\"forecast\",make_reduction(regressor, window_length=5, strategy=\"recursive\"))])\n",
    "    return forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------Fitting an Auto Regressive Light-GBM------------\n",
    "# Objectives can be :- regression, regression_l1, huber, fair, poisson, quantile, mape, gamma, tweedie, binary, multiclass,\n",
    "# multiclassova, cross_entropy, cross_entropy_lambda, lambdarank, rank_xendcg  \n",
    "\n",
    "# Setting objective as 'mape' here.\n",
    "\n",
    "params = {'objective':'quantile'}\n",
    "                               #A 10 percent and 90 percent prediction interval(0.1,0.9 respectively).\n",
    "alpha_params = [.1, .5, .9]    # Hyper-parameter \"alpha\" in Light GBM\n",
    "                               #Capture forecasts for 10th/median/90th quantile, respectively.\n",
    "for alpha in alpha_params:\n",
    "    \n",
    "    forecaster = get_transformed_target_forecaster(alpha,params)\n",
    "    \n",
    "    #Initialize ForecastingHorizon class to specify the horizon of forecast\n",
    "    fh = ForecastingHorizon(test.index, is_relative=False)\n",
    "    \n",
    "    #Fit on Training data.\n",
    "    forecaster.fit(train[time_dependent_variable])\n",
    "    \n",
    "    #Forecast the values.\n",
    "    y_pred = forecaster.predict(fh)\n",
    "    plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e1e5b",
   "metadata": {},
   "source": [
    "Now let's use lightGBM as a normal machine learning technique with input and output variables...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d82c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = lgb.LGBMRegressor().fit(train_X, train_Y)\n",
    "pred = rg.predict(test_X)\n",
    "plot_ml()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e03119",
   "metadata": {},
   "source": [
    "### 2) Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542639cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = AdaBoostRegressor().fit(train_X, train_Y)\n",
    "pred = rg.predict(test_X)\n",
    "plot_ml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2667e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(AdaBoostRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf930d11",
   "metadata": {},
   "source": [
    "### 3) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b268ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = xg.XGBRegressor().fit(train_X, train_Y)\n",
    "pred = rg.predict(test_X)\n",
    "plot_ml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(xg.XGBRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f145aa48",
   "metadata": {},
   "source": [
    "### 4) Bagged Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = BaggingRegressor().fit(train_X, train_Y)\n",
    "pred = rg.predict(test_X)\n",
    "plot_ml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dae74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(BaggingRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d224f7",
   "metadata": {},
   "source": [
    "### 5) GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade9180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = GradientBoostingRegressor().fit(train_X, train_Y)\n",
    "pred = rg.predict(test_X)\n",
    "plot_ml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f97ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(GradientBoostingRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b77d5",
   "metadata": {},
   "source": [
    "### 6) Extra TreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c45b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = ExtraTreesRegressor().fit(train_X, train_Y)\n",
    "pred = rg.predict(test_X)\n",
    "plot_ml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de30979",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(ExtraTreesRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879fb3e8",
   "metadata": {},
   "source": [
    "### 7) Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c78a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = DecisionTreeRegressor().fit(train_X, train_Y)\n",
    "pred = rg.predict(test_X)\n",
    "plot_ml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d2d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(DecisionTreeRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de608f",
   "metadata": {},
   "source": [
    "### 8) Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2)).fit(train_X, train_Y)\n",
    "pred = rg.predict(test_X)\n",
    "plot_ml()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e7de76",
   "metadata": {},
   "source": [
    "### 9) KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158196df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = KNeighborsRegressor(n_neighbors=5).fit(train_X, train_Y)\n",
    "pred = rg.predict(test_X)\n",
    "plot_ml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(KNeighborsRegressor(n_neighbors=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69936fe1",
   "metadata": {},
   "source": [
    "### 10) Random Forest Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = RandomForestRegressor().fit(train_X, train_Y)\n",
    "pred = rg.predict(test_X)\n",
    "plot_ml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a67d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(RandomForestRegressor())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
