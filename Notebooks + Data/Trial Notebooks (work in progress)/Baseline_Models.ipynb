{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e66a6bf",
   "metadata": {},
   "source": [
    "# NAIVE FORECASTING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d96ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import math\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to use this notebook for univarate time series analysis :-\n",
    "# 1) The primary requirement is not to have missing values or categorial(string) data for time_dependent variable \n",
    "#    and time_column.\n",
    "# 2) This cell requires information on file_name (only csv), time_dependent_variable, time_column, date_time format (frmt)\n",
    "#    and resample grain(X). After filling the required information correctly, you can run all the cells (Cell ---> Run All)\n",
    "# 3) Example :-\n",
    "#   file_name               = \"JetRail Avg Hourly Traffic Data - 2012-2013.csv\"\n",
    "#   time_dependent_variable = \"Count\"    (column name in your dataset)\n",
    "#   time_column             = \"Datetime\" (column name in your dataset)\n",
    "#   frmt                    = \"%Y-%m-%d\"\n",
    "#   X                       = \"D\" \n",
    "\n",
    "file_name = \"Monthly Production of Chocolate - Australia.csv\"\n",
    "time_dependent_variable = \"Volume\"\n",
    "time_column = \"Month\"\n",
    "frmt =  '%Y-%m'\n",
    "X = \"M\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a06eb9",
   "metadata": {},
   "source": [
    "### Reading the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f3fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(time_column, file_name, frmt='%Y-%m-%d %H:%M:%S', X= \"D\"):\n",
    "    df = pd.read_csv(file_name, parse_dates= True)\n",
    "    df = df[[time_column,time_dependent_variable]]\n",
    "    df[time_column] = pd.to_datetime(df[time_column],format=frmt) \n",
    "    df.index = df[time_column]\n",
    "    df = df.resample(X).mean()\n",
    "    df.reset_index(inplace= True)\n",
    "    return df\n",
    "df = data(time_column, file_name, frmt, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb628c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7dcde",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test using (you can use any one of them) :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This splits the data into train and test using default split_size = 0.7\n",
    "def train_test_split_perc(df, split= 0.7):\n",
    "    total_size=len(df)\n",
    "    train_size=math.floor(split*total_size) #(70% Dataset)\n",
    "    train = df.head(train_size)\n",
    "    test  = df.tail(len(df) -train_size)\n",
    "    return test,train\n",
    "    \n",
    "test,train = train_test_split_perc(df, split= 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090be446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This splits the data into train and test using split_date\n",
    "def train_test_split_date(df, split_date):\n",
    "    split_date = '2017-01-01'\n",
    "    train = df.loc[df.index <= split_date].copy()\n",
    "    test = df.loc[df.index > split_date].copy()\n",
    "    return train, test\n",
    "\n",
    "#test,train = train_test_split_date(df, split_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5121a33",
   "metadata": {},
   "source": [
    "### Evaluating the naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef5e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation Metrics :-\n",
    "# • Mean squared error (MSE) tells you how close a regression line is to a set of points. It does this by taking the distances\n",
    "#   from the points to the regression line (these distances are the errors) and squaring them. The closer to zero the error is,\n",
    "#   the better the model.\n",
    "# • Mean absolute error (MAE) measures the average magnitude of the errors in a set of predictions, without considering their\n",
    "#   direction. The closer to zero the error is, the better the model.\n",
    "# • Root mean square error (RMSE) is a quadratic scoring rule that also measures the average magnitude of the error. It’s the \n",
    "#   square root of the average of squared differences between prediction and actual observation. The closer to zero the error is\n",
    "#   ,the better the model.\n",
    "# • Mean absolute percentage error (MAPE) is a statistical measure of how accurate a forecast system is. It is a measure in\n",
    "#   terms of percentage. It is mostly used for time-series forecasting. The closer to zero the error is, the better the model.\n",
    "# • R-squared determines the proportion of variance in the dependent variable that can be explained by the independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8995d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
    "    def mean_absolute_percentage_error(y_true, y_pred):\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print('Evaluation metric results:-')\n",
    "    print(f'MSE is : {metrics.mean_squared_error(y_true, y_pred)}')\n",
    "    print(f'MAE is : {metrics.mean_absolute_error(y_true, y_pred)}')\n",
    "    print(f'RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}')\n",
    "    print(f'MAPE is : {mean_absolute_percentage_error(y_true,y_pred)}')\n",
    "    print(f'R2 is : {metrics.r2_score(y_true, y_pred)}',end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f072b92",
   "metadata": {},
   "source": [
    "### One-Step Baseline Model : Naive ( Strategy = Last) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e69c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is a one-step time series forecasting model. It can be treated as a baseline for one-step forecasting models. \n",
    "# y_pred(t) = y(t-1)\n",
    "\n",
    "def naive_forecaster(strategy = \"last\", step = \"single\"):\n",
    "    test_df = pd.concat([test,test[time_dependent_variable].shift(1)],axis=1) \n",
    "    test_df = test_df.dropna()\n",
    "    test_df.columns = [time_column,time_dependent_variable,\"prediction\"]\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(train[time_column], train[time_dependent_variable], label='Train',linewidth=2)\n",
    "    plt.plot(test_df[time_column],test_df[time_dependent_variable], label='Test',linewidth=2)\n",
    "    plt.plot(test_df[time_column],test_df['prediction'], label='Naive Strategy = last',linewidth=1)\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"One-Step Naive Forecast\")\n",
    "    plt.show()\n",
    "    return timeseries_evaluation_metrics_func(test_df[time_dependent_variable],test_df[\"prediction\"])\n",
    "    \n",
    "naive_forecaster()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e489aa",
   "metadata": {},
   "source": [
    "### Multi-Step Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec376af",
   "metadata": {},
   "source": [
    "##### 1)  Naive Forecasting Model (Strategy = last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05455f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For naïve forecasts, we simply set all forecasts to be the value of the last observation. This method works remarkably well\n",
    "# for many economic and financial time series.\n",
    "\n",
    "# Formula :-\n",
    "# y_hat(T+h|T) = yT\n",
    "\n",
    "def naive_forecastor(strategy = \"last\", step = \"multi\"):\n",
    "    dd = np.asarray(train[time_dependent_variable])\n",
    "    lastvalue = dd[len(dd)-1]\n",
    "    y_hat = test.copy()\n",
    "    y_hat['naive'] = lastvalue\n",
    " \n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(train[time_column], train[time_dependent_variable], label='Train')\n",
    "    plt.plot(test[time_column],test[time_dependent_variable], label='Test')\n",
    "    plt.plot(y_hat[time_column],y_hat['naive'], label='Naive Strategy = last')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"Multi-Step Naive Forecast\")\n",
    "    plt.show()\n",
    "    return timeseries_evaluation_metrics_func(test[time_dependent_variable],y_hat.naive)\n",
    "\n",
    "naive_forecastor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6af826",
   "metadata": {},
   "source": [
    "#### 2) Simple Average Forecasting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631360b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The forecasts of all future values are equal to the average (or “mean”) of the historical data. It is a useful baseline for \n",
    "# multi-step models.\n",
    "\n",
    "def simple_average(strategy = \"average\", step = \"multi\"):\n",
    "    y_hat = test.copy()\n",
    "    y_hat['simple_avg'] = train[time_dependent_variable].mean()\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(train[time_column], train[time_dependent_variable], label='Train')\n",
    "    plt.plot(test[time_column],test[time_dependent_variable], label='Test')\n",
    "    plt.plot(y_hat[time_column],y_hat['simple_avg'], label='Naive Average Forecasting')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"Simple Average Forecast\")\n",
    "    plt.show()\n",
    "    return timeseries_evaluation_metrics_func(test[time_dependent_variable],y_hat.simple_avg)\n",
    "\n",
    "simple_average()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf748a",
   "metadata": {},
   "source": [
    "#### 3) Drift Method (Extrapolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc8bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It can be treated as a baseline for multi-step models.\n",
    "\n",
    "# Definition :-\n",
    "# A variation on the naïve method is to allow the forecasts to increase or decrease over time, where the amount of change over\n",
    "# time (called the drift) is set to be the average change seen in the historical data.\n",
    "\n",
    "# Formula :-\n",
    "# y_hat(T+h|T)= y(T)+h(y(T)−y(1)/T−1) where, T is the last value in the train dataset and h is referring to periods in the test \n",
    "# data\n",
    "\n",
    "def drift_method(strategy = \"Drift\", step = \"multi\"):\n",
    "    dd = np.asarray(train[time_dependent_variable])\n",
    "    lastvalue = dd[len(dd)-1]\n",
    "    firstvalue = dd[0]\n",
    "    y_hat = test.copy()\n",
    "    pred = []\n",
    "    for x in range(1,len(df)-len(dd)+1):\n",
    "        y = lastvalue + ((lastvalue - firstvalue)/((len(dd)-1)-0))*x\n",
    "        pred.append(y)\n",
    "    index = [i for i in range(len(dd),len(df))]    \n",
    "    pred = pd.Series(pred,index=index)\n",
    "    y_hat[\"pred\"] = pred\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(train[time_column], train[time_dependent_variable], label='Train')\n",
    "    plt.plot(test[time_column],test[time_dependent_variable], label='Test')\n",
    "    plt.plot(y_hat[time_column],y_hat['pred'], label='Drift Method Forecasting')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"Drift Method Forecast\")\n",
    "    plt.show()\n",
    "    return timeseries_evaluation_metrics_func(test[time_dependent_variable],y_hat.pred)\n",
    "\n",
    "drift_method()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
