{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting - Autoregressive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries used : pmdarima, statsmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles \n",
    "AR,MA, ARMA, ARIMA, SARIMA\n",
    "\n",
    "1. https://towardsdatascience.com/time-series-models-d9266f8ac7b0#:~:text=AR%2C%20MA%2C%20ARMA%2C%20and%20ARIMA%20models%20are%20used,over%20the%20historical%20data%20of%20observation%20overtime%20period.\n",
    "\n",
    "2. https://puneet166.medium.com/time-series-forecasting-how-to-predict-future-data-using-arma-arima-and-sarima-model-8bd20597cc7b#:~:text=ARIMA%2C%20ARMA%20and%20SARIMA%20are%20used%20for%20predict,how%20to%20do%20forecasting%20using%20these%20three%20models.\n",
    "\n",
    "By plotting ACF and PACF, we can find a suitable model with help of this table given below (after the series is stationary) :-\n",
    "\n",
    "| Model | ACF Pattern | PACF Pattern |\n",
    "| --- | --- | --- |\n",
    "| AR(p) | Exponential decay or damped sine wave pattern or both | Significant spike through first lag |\n",
    "| MA(q) | Significant spike through first lag | Exponential decay |\n",
    "| ARMA(1,1) | Exponential decay from lag 1 | Exponential decay from lag 1 |\n",
    "| ARMA(p,q) | Exponential decay | Exponential decay |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pmdarima\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "\n",
    "import pmdarima as pmd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import pmdarima as pmd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "from sklearn import metrics\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to use this notebook for univarate time series analysis :-\n",
    "# 1) The primary requirement is not to have missing values or categorial(string) data for time_dependent variable \n",
    "#    and time_column.\n",
    "# 2) This cell requires information on file_name (only csv), time_dependent_variable, time_column, date_time format (frmt)\n",
    "#    and resample grain(X). After filling the required information correctly, you can run all the cells (Cell ---> Run All)\n",
    "# 3) Example :-\n",
    "#   file_name               = \"JetRail Avg Hourly Traffic Data - 2012-2013.csv\"\n",
    "#   time_dependent_variable = \"Count\"    (column name in your dataset)\n",
    "#   time_column             = \"Datetime\" (column name in your dataset)\n",
    "#   frmt                    = \"%Y-%m-%d\"\n",
    "#   X                       = \"D\" \n",
    "\n",
    "file_name = \"Prime.xlsx\"\n",
    "time_dependent_variable = \"Liq Rate\"\n",
    "time_column = \"Date\"\n",
    "frmt =  '%b-%y'\n",
    "X = \"M\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(time_column, file_name, frmt='%Y-%m-%d %H:%M:%S', X=\"D\"):\n",
    "    if \".csv\" in file_name:\n",
    "        df = pd.read_csv(file_name, parse_dates=True)\n",
    "    elif \".xlsx\" in file_name:\n",
    "        df = pd.read_excel(file_name, parse_dates=True)\n",
    "\n",
    "    df = df[[time_column, time_dependent_variable]]\n",
    "    df[time_column] = pd.to_datetime(df[time_column], format=frmt)\n",
    "    df.index = df[time_column]\n",
    "    df = df.resample(X).mean()\n",
    "    df.reset_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = data(time_column, file_name, frmt, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This splits the data into train and test using default split_size = 0.7\n",
    "def train_test_split_perc(df, split= 0.7):\n",
    "    total_size=len(df)\n",
    "    train_size=math.floor(split*total_size) #(70% Dataset)\n",
    "    train = df.head(train_size)\n",
    "    test  = df.tail(len(df) -train_size)\n",
    "    return test,train\n",
    "    \n",
    "test,train = train_test_split_perc(df, split= 0.8)\n",
    "y_hat = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also split the training data using split date\n",
    "def train_test_split_date(df, split_date):\n",
    "    train = df.loc[df.index <= split_date].copy()\n",
    "    test = df.loc[df.index > split_date].copy()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic Model Selection with AIC/BIC in Python\n",
    "\n",
    "Article :https://medium.com/analytics-vidhya/probabilistic-model-selection-with-aic-bic-in-python-f8471d6add32#:~:text=AIC%20and%20BIC%20techniques%20can%20be%20implemented%20in,statsmodels.formula.api%20provides%20a%20direct%20approach%20to%20compute%20aic%2Fbic.\n",
    "Video : https://campus.datacamp.com/courses/arima-models-in-python/chapter-3-the-best-of-the-best-models?ex=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
    "    def mean_absolute_percentage_error(y_true, y_pred):\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print('Evaluation metric results:-')\n",
    "    print(f'MSE is : {metrics.mean_squared_error(y_true, y_pred)}')\n",
    "    print(f'MAE is : {metrics.mean_absolute_error(y_true, y_pred)}')\n",
    "    print(f'RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}')\n",
    "    print(f'MAPE is : {mean_absolute_percentage_error(y_true,y_pred)}')\n",
    "    print(f'R2 is : {metrics.r2_score(y_true, y_pred)}',end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics_func(y_true, y_pred):\n",
    "    return {\"MAPE\": np.mean(np.abs((y_true - y_pred) / y_true)) * 100,\n",
    "            \"MSE\": metrics.mean_squared_error(y_true, y_pred),\n",
    "            \"RMSE\": np.sqrt(metrics.mean_squared_error(y_true, y_pred)),\n",
    "            \"MAE\": metrics.mean_absolute_error(y_true, y_pred),\n",
    "            \"R2\": metrics.r2_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def plot(method):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(train[time_column], train[time_dependent_variable], label='Train')\n",
    "    plt.plot(test[time_column],test[time_dependent_variable], label='Test')\n",
    "    plt.plot(y_hat[time_column],y_hat[method], label= method +' forecast')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(method + ' forecast')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want only specific list of lags like 1 & 3 as AR components, then you can do that in the following way :-\n",
    "\n",
    "https://stackoverflow.com/questions/55882111/arima-model-for-certain-lags\n",
    "\n",
    "https://towardsdatascience.com/advanced-time-series-analysis-with-arma-and-arima-a7d9b589ed6d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By set dynamic = true, prediction would be one-step recursive\n",
    "\n",
    "def ar(lags,trend=\"ct\", dynamic=True, method = \"AR\"):\n",
    "    model = AutoReg(train[time_dependent_variable], lags=lags, trend= trend)\n",
    "    fit1 = model.fit()\n",
    "    y_hat[method] = fit1.predict(start=len(train), end=len(train)+len(test)-1, dynamic=dynamic)\n",
    "    return evaluation_metrics_func(test[time_dependent_variable], y_hat[method])\n",
    "\n",
    "ar(lags= 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregressive Model ( Seasonality = True)\n",
    "\n",
    "Specify the number of periods as well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar_seasonal(lags, period = 7,trend=\"ct\", method = \"ARS\"):\n",
    "    model = AutoReg(train[time_dependent_variable], lags=lags, trend= trend, seasonal=True, period = period)\n",
    "    fit1 = model.fit()\n",
    "    y_hat[method] = fit1.predict(start=len(train), end=len(train)+len(test)-1, dynamic=True)\n",
    "    #plot(method)\n",
    "    return evaluation_metrics_func(test[time_dependent_variable], y_hat[method])\n",
    "\n",
    "ar_seasonal(lags= 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar_best_params( p_values=range(40), basis = \"MAPE\"):\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for p in p_values:\n",
    "        order = (p,)\n",
    "        try:\n",
    "            metric = ar_seasonal(*order)[basis]  # you can also choose ar_seasonal() here\n",
    "            if metric < best_score:\n",
    "                best_score, best_cfg = metric, order\n",
    "            print('AR%s metric=%.3f' % (order,metric))\n",
    "        except:\n",
    "            continue\n",
    "    print('Best AR%s metric=%.3f' % (best_cfg, best_score))\n",
    "    return best_cfg\n",
    "    \n",
    "best_cfg = ar_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_seasonal(*best_cfg)\n",
    "plot(method= 'AR' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA with pmdarima library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_ma(max_q = 40, trend=\"ct\", summary= True, method = \"MA\"):\n",
    "    model = pmd.auto_arima(train[time_dependent_variable], \n",
    "                          start_p=0, \n",
    "                          start_q=2,\n",
    "                          d = 0,\n",
    "                           max_p = 0, max_q=max_q, seasonal=False,trend = trend,\n",
    "                            trace=True,error_action='ignore',\n",
    "                          suppress_warnings=True,stepwise=True)\n",
    "    if summary : print(model.summary())\n",
    "    y_hat[method] = model.predict(len(test))\n",
    "    return evaluation_metrics_func(test[time_dependent_variable], y_hat[method])\n",
    "    \n",
    "auto_ma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(method = \"MA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARMA with pmdarima library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_arma(max_p = 7, max_q= 7, summary= False,trend=\"ct\", method = \"ARMA\"):\n",
    "    model = pmd.auto_arima(train[time_dependent_variable], \n",
    "                          start_p=1, \n",
    "                          start_q=1,\n",
    "                           d = 0,\n",
    "                           max_p = max_p, max_q = max_q,\n",
    "                           seasonal=False, trend = trend,\n",
    "                           trace=True,error_action='ignore',\n",
    "                          suppress_warnings=True,stepwise=True)\n",
    "    if summary : print(model.summary())\n",
    "    y_hat[method] = model.predict(len(test))\n",
    "    return evaluation_metrics_func(test[time_dependent_variable], y_hat[method])\n",
    "    \n",
    "auto_arma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(method = \"ARMA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima(p,d,q, summary = False, method = \"ARIMA\" ):\n",
    "    model = ARIMA(train[time_dependent_variable], exog=None, order=(p,d,q))\n",
    "    fit1 = model.fit()\n",
    "    if summary: print(fit1.summary())\n",
    "    y_hat[method] = fit1.predict(start=len(train), end=len(train)+len(test)-1, dynamic=True, typ='levels')\n",
    "    return evaluation_metrics_func(test[time_dependent_variable], y_hat[method])\n",
    "\n",
    "arima(1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_best_params(p_values=range(7), d_values=range(2), q_values=range(7),basis = \"MAE\"):\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    pdq = list(itertools.product(p_values, d_values, q_values))\n",
    "    for order in pdq:\n",
    "                try:\n",
    "                    metric = arima(*order)[basis]\n",
    "                    if metric < best_score:\n",
    "                        best_score, best_cfg = metric, order\n",
    "                    print('ARIMA%s metric=%.3f' % (order,metric))\n",
    "                except:\n",
    "                    continue\n",
    "    print('Best ARIMA%s metric=%.3f' % (best_cfg, best_score))\n",
    "    return best_cfg\n",
    "    \n",
    "best_cfg = arima_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima(*best_cfg, summary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(method= 'ARIMA' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA with pmdarima library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Pmdarima (for py + arima) is a statistical library designed to fill the void in Python’s time-series analysis capabilities, which is the equivalent of R’s auto.arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_arima(max_p= 7, max_q=7, summary= False,  method = \"PMD_ARIMA\"):\n",
    "    model = pmd.auto_arima(train[time_dependent_variable], \n",
    "                          start_p=1, \n",
    "                          start_q=1,\n",
    "                           max_p=max_p, max_q=max_q,\n",
    "                           seasonal=False, \n",
    "                           d=None, trace=True,error_action='ignore',\n",
    "                          suppress_warnings=True,stepwise=True)\n",
    "    if summary : print(model.summary())\n",
    "    y_hat[method] = model.predict(len(test))\n",
    "    return evaluation_metrics_func(test[time_dependent_variable], y_hat[method])\n",
    "    \n",
    "auto_arima()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(method=  \"PMD_ARIMA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m refers to the number of periods in each season.\n",
    "\n",
    "• 7 → Daily\n",
    "\n",
    "• 12 → Monthly\n",
    "\n",
    "• 52 → Weekly\n",
    "\n",
    "• 4 → Quarterly\n",
    "\n",
    "• 1 → Annual (non-seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarima(p,d,q, P, D, Q, M, method = \"SARIMA\"):\n",
    "    model = SARIMAX(train[time_dependent_variable], order=(p,d,q),  seasonal_order=(P,D,Q,M))\n",
    "    fit1 = model.fit()\n",
    "    y_hat[method] = fit1.predict(start=len(train), end=len(train)+len(test)-1, dynamic=True, typ='levels')\n",
    "    return evaluation_metrics_func(test[time_dependent_variable], y_hat[method])\n",
    "\n",
    "sarima(1, 1, 1, 1, 1, 3, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning : Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sarima_best_params(p_values=range(2), d_values=range(2), q_values=range(2), P_values=range(2), D_values=range(2), Q_values=range(2), basis=\"MAE\"):\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    M = [7,30]\n",
    "    pdqPDQM = list(itertools.product(p_values, d_values, q_values, P_values, D_values, Q_values, M))\n",
    "    for order in pdqPDQM:\n",
    "        try:\n",
    "            metric = sarima(*order)[basis]\n",
    "            if metric < best_score:\n",
    "                 best_score, best_cfg = metric, order\n",
    "                 print('ARIMA%s metric=%.3f' % (order,metric))\n",
    "        except:\n",
    "            continue\n",
    "    print('Best ARIMA%s metric=%.3f' % (best_cfg, best_score))\n",
    "    return best_cfg \n",
    "    \n",
    "best_cfg = sarima_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_cfg)\n",
    "sarima(*best_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(method = \"SARIMA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMA using pmdarima library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_sarima(m, max_p= 3, max_q= 3, max_P=3 , max_Q=3 , summary= False, method = \"PMD_SARIMA\"):\n",
    "    model = pmd.auto_arima(train[time_dependent_variable], \n",
    "                               start_p=1, start_q=1,\n",
    "                                max_p=max_p, max_q=max_q, seasonal=True, start_P=1,\n",
    "                                start_Q=1, max_P=max_P, max_D=7, max_Q=max_Q, m=m,\n",
    "                                d=None, D=None, trace=True, error_action='ignore', \n",
    "                                suppress_warnings=True,\n",
    "                                stepwise=True)\n",
    "    if summary : print(model.summary())\n",
    "    y_hat[method] = model.predict(len(test))\n",
    "    return evaluation_metrics_func(test[time_dependent_variable], y_hat[method])\n",
    "\n",
    "auto_sarima(m = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_sarima_best_seasonal_params(basis = \"MAE\"):\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for m in [1,4,7,12,52]:\n",
    "        print(\"=\"*100)\n",
    "        print(f' Fitting SARIMA for Seasonal value m = {str(m)}')\n",
    "        order = m\n",
    "        try:\n",
    "            metric = auto_sarima(m= m)[basis]\n",
    "            if metric < best_score:\n",
    "                best_score, best_cfg = metric, order\n",
    "            print('SARIMA%s metric=%.3f' % (order,metric))\n",
    "        except:\n",
    "            continue\n",
    "    print('Best SARIMA%s metric=%.3f' % (best_cfg, best_score))\n",
    "    return best_cfg\n",
    "    \n",
    "best_cfg = auto_sarima_best_seasonal_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_sarima(m = best_cfg, summary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(method=  \"PMD_SARIMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
