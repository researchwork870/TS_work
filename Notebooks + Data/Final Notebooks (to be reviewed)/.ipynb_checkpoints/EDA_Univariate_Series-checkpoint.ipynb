{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# EDA FOR UNIVARIATE TIME SERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import calendar\n",
    "import os\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# time series analysis\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to use this notebook for univarate time series analysis :-\n",
    "# 1) The primary requirement is not to have missing values or categorial(string) data for time_dependent variable \n",
    "#    and time_column.\n",
    "# 2) This cell requires information on file_name (only csv), time_dependent_variable, time_column, date_time format (frmt)\n",
    "#    and resample grain(X). After filling the required information correctly, you can run all the cells (Cell ---> Run All)\n",
    "# 3) Example :-\n",
    "#   file_name               = \"JetRail Avg Hourly Traffic Data - 2012-2013.csv\"\n",
    "#   time_dependent_variable = \"Count\"    (column name in your dataset)\n",
    "#   time_column             = \"Datetime\" (column name in your dataset)\n",
    "#   frmt                    = \"%Y-%m-%d\"\n",
    "#   X                       = \"D\" \n",
    "\n",
    "file_name = \"Prime.xlsx\"\n",
    "time_dependent_variable = \"Liq Rate\"\n",
    "time_column = \"Date\"\n",
    "frmt =  '%b-%y'\n",
    "X = \"M\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(time_column, file_name, frmt='%Y-%m-%d %H:%M:%S', X= \"D\"):\n",
    "    df = pd.read_excel(file_name, parse_dates= True)\n",
    "    df = df[[time_column,time_dependent_variable]]\n",
    "    df[time_column] = pd.to_datetime(df[time_column],format=frmt) \n",
    "    df.index = df[time_column]\n",
    "    df = df.resample(X).mean()\n",
    "    df.reset_index(inplace= True)\n",
    "    return df\n",
    "df = data(time_column, file_name, frmt,X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumetable(df):\n",
    "    print(f\"Dataset Shape: {df.shape}\")\n",
    "    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n",
    "    summary = summary.reset_index()\n",
    "    summary['Name'] = summary['index']\n",
    "    summary = summary[['Name','dtypes']]\n",
    "    summary['Missing'] = df.isnull().sum().values\n",
    "    summary['Missing(% of Total values)']= (100 * summary['Missing']) / df.shape[0]\n",
    "    summary['Uniques'] = df.nunique().values\n",
    "    summary['First Value'] = df.loc[0].values\n",
    "    summary['Second Value'] = df.loc[1].values\n",
    "    return summary\n",
    "resumetable(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(df):\n",
    "    return df.describe().T\n",
    "describe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the Time series data\n",
    "def graph(time_column, time_dependent_variable):\n",
    "    global df\n",
    "    fig, ax = plt.subplots(figsize=(20,7))\n",
    "    a = sns.lineplot(x=time_column, y=time_dependent_variable, data=df)\n",
    "    a.set_title(\"Daily Data\",fontsize=15)\n",
    "    plt.show()\n",
    "graph(time_column, time_dependent_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates time series features from Date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_features(df, time_column, time_dependent_variable):\n",
    "    df = df.copy()\n",
    "\n",
    "    \n",
    "    df['month'] = df[time_column].dt.strftime('%B')\n",
    "    df['year'] = df[time_column].dt.strftime('%Y')\n",
    "    df['dayofweek'] = df[time_column].dt.strftime('%A')\n",
    "    df['quarter'] = df[time_column].dt.quarter\n",
    "    df['dayofyear'] = df[time_column].dt.dayofyear\n",
    "    df['dayofmonth'] = df[time_column].dt.day\n",
    "    df['weekofyear'] = df[time_column].dt.weekofyear\n",
    "    \n",
    "\n",
    "    return df\n",
    "df_new = date_features(df, time_column, time_dependent_variable)\n",
    "\n",
    "df_new.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Features to see trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(time_column, time_dependent_variable):\n",
    "    fig, ax = plt.subplots(figsize=(14,5))\n",
    "    palette = sns.color_palette(\"mako_r\", 4)\n",
    "    a = sns.barplot(x=\"month\", y=time_dependent_variable, hue = 'year',data=df_new)\n",
    "    a.set_title(time_dependent_variable+\" \"+ \"data\",fontsize=15)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "eda(time_column, time_dependent_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregated EDA of the MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def aggregated_eda(time_feature, rotation= 40 ,color = \"#D39200\"):\n",
    "    plt.xticks(rotation=rotation)\n",
    "\n",
    "    x=df_new.groupby([time_feature], as_index=False).agg({time_dependent_variable:'sum'})\n",
    "    sns.barplot(x = x[time_feature], y = time_dependent_variable, data = x, order= x.sort_values(time_dependent_variable)[time_feature], color = color)\n",
    "    plt.xticks(rotation=rotation)\n",
    "    plt.title(time_dependent_variable +\" \" + \"per \" + time_feature, fontsize=14)\n",
    "    plt.ylabel(time_dependent_variable, fontsize=14)\n",
    "    plt.xlabel(time_feature, fontsize=14)\n",
    "    plt.show()\n",
    "    del x\n",
    "    \n",
    "    \n",
    "for time_feature in [\"month\", \"quarter\", \"dayofweek\", \"year\"]:\n",
    "    aggregated_eda(time_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern with Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring quarterly pattern if any:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarterly_pattern_over_years(time_column, time_dependent_variable, rotation=0, color = \"#D39200\"): \n",
    "    for year in df[time_column].dt.year.unique():\n",
    "        #Filtering data for specific year\n",
    "        x = df[df[time_column].dt.year == year]\n",
    "\n",
    "        #Extracting month name from date\n",
    "        x['quarter']=x[time_column].dt.quarter\n",
    "\n",
    "        #Grouping data by months and adding time_dependent_variable\n",
    "        x=x.groupby(['quarter'], as_index=False).agg({time_dependent_variable:'sum'})\n",
    "\n",
    "\n",
    "\n",
    "        #Plotting month Vs time_dependent_variablefor every year\n",
    "        #plt.figure(figsize=(12,8))\n",
    "        sns.barplot(x = x.quarter, y = time_dependent_variable, data = x, order= x.sort_values(time_dependent_variable).quarter, color = color)\n",
    "        plt.xticks(rotation=rotation)\n",
    "        plt.title(time_dependent_variable +\" \" + \"per quarter (\"+str(year)+\")\",fontsize=14)\n",
    "        plt.ylabel(time_dependent_variable, fontsize=14)\n",
    "        plt.xlabel('quarter',fontsize=14)\n",
    "        plt.show()\n",
    "        del x\n",
    "quarterly_pattern_over_years(time_column, time_dependent_variable )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring montly pattern if any:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " def montly_pattern_over_years(time_column, time_dependent_variable, rotation=70, color = \"#D39200\"): \n",
    "    for year in df[time_column].dt.year.unique():\n",
    "        #Filtering data for specific year\n",
    "        x = df[df[time_column].dt.year == year]\n",
    "\n",
    "        #Extracting month name from date\n",
    "        x['month']=x[time_column].dt.month_name()\n",
    "\n",
    "        #Grouping data by months and adding time_dependent_variable\n",
    "        x=x.groupby(['month'], as_index=False).agg({time_dependent_variable:'sum'})\n",
    "\n",
    "\n",
    "\n",
    "        #Plotting month Vs time_dependent_variable for every year\n",
    "        #plt.figure(figsize=(12,8))\n",
    "        sns.barplot(x = x.month, y = time_dependent_variable, data = x, order= x.sort_values(time_dependent_variable).month, color = color)\n",
    "        plt.xticks(rotation=rotation)\n",
    "        plt.title(time_dependent_variable +\" \" + \"per Month (\"+str(year)+\")\",fontsize=14)\n",
    "        plt.ylabel(time_dependent_variable, fontsize=14)\n",
    "        plt.xlabel('Month',fontsize=14)\n",
    "        plt.show()\n",
    "        del x\n",
    "montly_pattern_over_years(time_column, time_dependent_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring weekly pattern if any:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekly_pattern_over_years(time_column, time_dependent_variable , rotation=70, color = \"#D39200\"):\n",
    "    for year in df[time_column].dt.year.unique():\n",
    "        \n",
    "        #Filtering data for specific year\n",
    "        x = df[df[time_column].dt.year == year]\n",
    "\n",
    "        #Adding Day of Week as a Feature\n",
    "        x['day_of_week'] = x[time_column].dt.day_name()\n",
    "        \n",
    "        # Group By day_of_week and Sum of time_dependent_variable for each day_of_week\n",
    "        x = x.groupby(['day_of_week'], as_index=False).agg({time_dependent_variable:'sum'})\n",
    "\n",
    "\n",
    "        #Plotting day_of_week Vs time_dependent_variable\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sns.barplot(x = x.day_of_week, y = time_dependent_variable, data = x, order= x.sort_values(time_dependent_variable).day_of_week, color = color)\n",
    "        plt.title(time_dependent_variable+\" \"+ \"per Day of week (\"+str(year)+\")\", fontsize= 14)\n",
    "        plt.xlabel('Day of week', fontsize= 14)\n",
    "        plt.ylabel(time_dependent_variable, fontsize= 14)\n",
    "\n",
    "        del x\n",
    "weekly_pattern_over_years(time_column, time_dependent_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA of the Variable to be Forecasted (time_dependent_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(time_column, inplace= True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up plot functions\n",
    "def plt_( time_dependent_variable, dataset= df):    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(dataset[time_dependent_variable], color = 'b')\n",
    "    plt.show()\n",
    "    \n",
    "def density_plt_(time_dependent_variable, dataset= df ):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.distplot(dataset[time_dependent_variable])\n",
    "    plt.show()\n",
    "    \n",
    "#Decomposition\n",
    "def decomp_plt_(time_dependent_variable, dataset= df ,freq = 12,  model='multiplicative'):\n",
    "    decomposition = seasonal_decompose(dataset[time_dependent_variable], freq = 12, model=model) #Can't handle missing data\n",
    "    fig = plt.figure(figsize = (20, 10))\n",
    "    ax = fig.add_subplot(411)\n",
    "    ax.plot(dataset[time_dependent_variable], label='Original', color = 'b')\n",
    "    ax.legend(loc='best')\n",
    "    ax = fig.add_subplot(412)\n",
    "    ax.plot(decomposition.trend, label='Trend', color = 'b')\n",
    "    ax.legend(loc='best')\n",
    "    ax = fig.add_subplot(413)\n",
    "    ax.plot(decomposition.seasonal,label='Seasonality', color = 'b')\n",
    "    ax.legend(loc='best')\n",
    "    ax= fig.add_subplot(414)\n",
    "    ax.plot(decomposition.resid, label='Residuals', color = 'b')\n",
    "    ax.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_( time_dependent_variable)\n",
    "density_plt_( time_dependent_variable)\n",
    "decomp_plt_( time_dependent_variable,df,freq = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing For Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF  -> It is a function that provides you with the information of how much a series is autocorrelated with its lagged values.\n",
    "#         In simple terms, it describes how well the present value of the series is related with its past values.\n",
    "# PACF -> It is another important function that finds correlation of the residuals with the next lag. It is a function that\n",
    "#         measures the incremental benefit of adding another lag. So if through the PACF function we discover that there \n",
    "#         is hidden information in the residual that can be modeled by the next lag, we will keep that next lag as a feature \n",
    "#         while modeling.\n",
    "\n",
    "def acf_pacf_plot(df, time_dependent_variable, lags=40):  \n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    fig = sm.graphics.tsa.plot_acf(df[time_dependent_variable], lags=lags, ax=ax1) # \n",
    "    ax2 = fig.add_subplot(212)\n",
    "    fig = sm.graphics.tsa.plot_pacf(df[time_dependent_variable], lags=lags, ax=ax2)# , lags=40\n",
    "acf_pacf_plot(df, time_dependent_variable, lags=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Dickey-Fuller test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Augmented Dickey-Fuller test can be used to test for a unit root in a univariate processin the presence of \n",
    "# serial correlation.\n",
    "\n",
    "# Ho ---> It is non-stationary\n",
    "# H1 ---> It is stationary\n",
    "\n",
    "# Caveat : Can't handle missing data\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller \n",
    "\n",
    "def test_stationarity(df, time_dependent_variable, window = 7, cutoff = 0.01, maxlag=20, regression=\"c\",autolag= \"AIC\",store=False,regresults=False):\n",
    "\n",
    "    #Determing rolling statistics\n",
    "    rolmean = df[time_dependent_variable].rolling(window).mean()\n",
    "    rolstd = df[time_dependent_variable].rolling(window).std()\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    orig = plt.plot(df[time_dependent_variable], color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation of '+ time_dependent_variable )\n",
    "    plt.show()\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    result=adfuller(df[time_dependent_variable],maxlag,regression,autolag,store,regresults)\n",
    "    labels = ['ADF Test Statistic','p-value','Lags Used','Number of Observations Used']\n",
    "    for value,label in zip(result,labels):\n",
    "        print(label+' : '+str(value) )\n",
    "    if result[1] <= cutoff:\n",
    "        print(\"Strong Evidence against the null hypothesis(Ho), reject the null hypothesis.\\nData has no unit root and is stationary\")\n",
    "    else:\n",
    "        print(\"Weak Evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \")\n",
    "    \n",
    "    \n",
    "test_stationarity(df, time_dependent_variable, window = 7, cutoff = 0.01, maxlag=10, regression=\"ct\",autolag= \"AIC\",store=False,regresults=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffencing using Augmented Dickey-Fuller test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differencing the time series is one of widely used remedies for making the series stationary. The function below performs the \n",
    "# differencing based on the Augmented Dickey-Fuller test to make the time series stationary. In other words, it finds the\n",
    "# smallest value of differencing level which makes the series stationary.\n",
    "\n",
    "\n",
    "def differencing_series(df, time_dependent_variable, no_of_differences= 4, window = 7, cutoff = 0.01, maxlag=30, regression=\"ct\",autolag= \"AIC\",store=False,regresults=False):\n",
    "    for i in range( 1, no_of_differences):\n",
    "        df[\"diff\"+ str(i)] = df[time_dependent_variable] - df[time_dependent_variable].shift(i)\n",
    "        df = df.dropna(inplace = False)\n",
    "        #Perform Dickey-Fuller test:\n",
    "        \n",
    "        result=adfuller(df[\"diff\"+ str(i)],maxlag,regression,autolag,store,regresults)\n",
    "\n",
    "        if result[1] <= cutoff:\n",
    "            test_stationarity(df, time_dependent_variable= \"diff\"+ str(i), window = window, cutoff = cutoff, maxlag=maxlag, regression=regression, autolag= autolag, store=False,regresults=False)\n",
    "            print((\"Differencing_level\"+' : '+str(i)))\n",
    "            fig = plt.figure(figsize=(12,8))\n",
    "            ax1 = fig.add_subplot(211)\n",
    "            fig = sm.graphics.tsa.plot_acf(df[\"diff\"+ str(i)], lags=10, ax=ax1)\n",
    "            ax2 = fig.add_subplot(212)\n",
    "            fig = sm.graphics.tsa.plot_pacf(df[\"diff\"+ str(i)], lags=10, ax=ax2)\n",
    "            \n",
    "            break\n",
    "        else:\n",
    "            test_stationarity(df, time_dependent_variable= \"diff\"+ str(i), window = window, cutoff = cutoff, maxlag=maxlag, regression=regression, autolag= autolag, store=False,regresults=False)\n",
    "\n",
    "df_difference = df.copy()        \n",
    "differencing_series(df_difference, time_dependent_variable, no_of_differences=4, window = 7, cutoff = 0.01, maxlag=10, regression=\"ct\",autolag= \"AIC\",store=False,regresults=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Differencing using Augmented Dickey-Fuller test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function below performs the seasonal differencing based on the Augmented Dickey-Fuller test \n",
    "# to make the time series stationary.\n",
    "\n",
    "# A seasonal difference is the difference between an observation and the corresponding observation from a previous year.\n",
    "# y'(t) = y(t) − y(t−m)\n",
    "\n",
    "def seasonal_differencing_series(df, time_dependent_variable, m1,m2,m3,m4, window = 7, cutoff = 0.01, maxlag=30, regression=\"ct\",autolag= \"AIC\",store=False,regresults=False):\n",
    "    for i in [m1,m2,m3,m4]:\n",
    "        df[\"diff\"+ str(i)] = df[time_dependent_variable] - df[time_dependent_variable].shift(i)\n",
    "        df = df.dropna(inplace = False)\n",
    "        #Perform Dickey-Fuller test:\n",
    "        \n",
    "        result=adfuller(df[\"diff\"+ str(i)],maxlag,regression,autolag,store,regresults)\n",
    "\n",
    "        if result[1] <= cutoff:\n",
    "            test_stationarity(df, time_dependent_variable= \"diff\"+ str(i), window = window, cutoff = cutoff, maxlag=maxlag, regression=regression, autolag= autolag, store=False,regresults=False)\n",
    "            print((\"Differencing_level\"+' : '+str(i)))\n",
    "            fig = plt.figure(figsize=(12,8))\n",
    "            ax1 = fig.add_subplot(211)\n",
    "            fig = sm.graphics.tsa.plot_acf(df[\"diff\"+ str(i)], lags=40, ax=ax1)\n",
    "            ax2 = fig.add_subplot(212)\n",
    "            fig = sm.graphics.tsa.plot_pacf(df[\"diff\"+ str(i)], lags=40, ax=ax2)\n",
    "            \n",
    "            break\n",
    "        else:\n",
    "            test_stationarity(df, time_dependent_variable= \"diff\"+ str(i), window = window, cutoff = cutoff, maxlag=maxlag, regression=regression, autolag= autolag, store=False,regresults=False)\n",
    "\n",
    "        \n",
    "seasonal_differencing_series(df, time_dependent_variable, m1=7,m2=14,m3=21,m4=28, window = 7, cutoff = 0.01, maxlag=10, regression=\"ct\",autolag= \"AIC\",store=False,regresults=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
