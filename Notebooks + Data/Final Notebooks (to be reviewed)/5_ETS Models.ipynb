{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ETS (ERROR, TREND AND SEASONALITY) MODELS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# libraries\r\n",
    "import pandas as pd \r\n",
    "import math\r\n",
    "import numpy as np \r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import datetime\r\n",
    "from sklearn import metrics\r\n",
    "from statsmodels.tsa.api import ExponentialSmoothing,SimpleExpSmoothing, Holt\r\n",
    "from statsmodels.tsa.forecasting.theta import ThetaModel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# In order to use this notebook for univarate time series analysis :-\r\n",
    "# 1) The primary requirement is not to have missing values or categorial(string) data for time_dependent variable \r\n",
    "#    and time_column.\r\n",
    "# 2) This cell requires information on file_name (only csv), time_dependent_variable, time_column, date_time format (frmt)\r\n",
    "#    and resample grain(X). After filling the required information correctly, you can run all the cells (Cell ---> Run All)\r\n",
    "# 3) Example :-\r\n",
    "#   file_name               = \"JetRail Avg Hourly Traffic Data - 2012-2013.csv\"\r\n",
    "#   time_dependent_variable = \"Count\"    (column name in your dataset)\r\n",
    "#   time_column             = \"Datetime\" (column name in your dataset)\r\n",
    "#   frmt                    = \"%Y-%m-%d\"\r\n",
    "#   X                       = \"D\" \r\n",
    "\r\n",
    "file_name = \"cta_ridership.csv\"\r\n",
    "time_dependent_variable = \"total_rides\"\r\n",
    "time_column = \"service_date\"\r\n",
    "frmt =  '%Y-%m-%d'\r\n",
    "X = \"D\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading the csv file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def data(time_column, file_name, frmt='%Y-%m-%d %H:%M:%S', X= \"D\"):\r\n",
    "    df = pd.read_csv(file_name, parse_dates= True)\r\n",
    "    df = df[[time_column,time_dependent_variable]]\r\n",
    "    df[time_column] = pd.to_datetime(df[time_column],format=frmt) \r\n",
    "    df.index = df[time_column]\r\n",
    "    df = df.resample(X).mean()\r\n",
    "    df.reset_index(inplace= True)\r\n",
    "    return df\r\n",
    "df = data(time_column, file_name, frmt, X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splitting the data into train and test using (you can use any one of them) :-"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# This splits the data into train and test using default split_size = 0.7\r\n",
    "def train_test_split_perc(df, split= 0.7):\r\n",
    "    total_size=len(df)\r\n",
    "    train_size=math.floor(split*total_size) #(70% Dataset)\r\n",
    "    train = df.head(train_size)\r\n",
    "    test  = df.tail(len(df) -train_size)\r\n",
    "    return test,train\r\n",
    "    \r\n",
    "test,train = train_test_split_perc(df, split= 0.8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# This splits the data into train and test using split_date\r\n",
    "def train_test_split_date(df, split_date):\r\n",
    "    split_date = '2017-01-01'\r\n",
    "    train = df.loc[df.index <= split_date].copy()\r\n",
    "    test = df.loc[df.index > split_date].copy()\r\n",
    "    return train, test\r\n",
    "\r\n",
    "#test,train = train_test_split_date(df, split_date)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluating a model using different metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn import metrics\r\n",
    "\r\n",
    "def timeseries_evaluation_metrics_func(y_true, y_pred):\r\n",
    "    def mean_absolute_percentage_error(y_true, y_pred):\r\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\r\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\r\n",
    "    print('Evaluation metric results:-')\r\n",
    "    print(f'MSE is : {metrics.mean_squared_error(y_true, y_pred)}')\r\n",
    "    print(f'MAE is : {metrics.mean_absolute_error(y_true, y_pred)}')\r\n",
    "    print(f'RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}')\r\n",
    "    print(f'MAPE is : {mean_absolute_percentage_error(y_true,y_pred)}')\r\n",
    "    print(f'R2 is : {metrics.r2_score(y_true, y_pred)}',end='\\n\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MODELS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) Single Exponential Smoothing Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fitting and forecasting a simple exponential model\r\n",
    "fitSESauto = SimpleExpSmoothing(np.asarray(train[time_dependent_variable])).fit(optimized= True)\r\n",
    "pred = fitSESauto.forecast(len(test))\r\n",
    "\r\n",
    "# Different metrics for evaluating the model\r\n",
    "print(timeseries_evaluation_metrics_func(test[time_dependent_variable],pred))\r\n",
    "print(fitSESauto.summary())\r\n",
    "\r\n",
    "# Creating a column for forecasts for plotting\r\n",
    "y_hat = test.copy()\r\n",
    "index = [i for i in range(len(train),len(df))]    \r\n",
    "pred = pd.Series(pred,index=index)\r\n",
    "y_hat[\"pred\"] = pred\r\n",
    "\r\n",
    "# Plotting a graph showing results\r\n",
    "plt.figure(figsize=(12,8))\r\n",
    "plt.plot(train[time_column], train[time_dependent_variable], label='Train')\r\n",
    "plt.plot(test[time_column],test[time_dependent_variable], label='Test')\r\n",
    "plt.plot(y_hat[time_column],y_hat['pred'], label='Simple Exponential Smoothing using optimized =True')\r\n",
    "plt.legend(loc='best')\r\n",
    "plt.title(\"Single Exponential Smoothing Forecast\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) Double Exponential Smoothing Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fitting and forecasting a double exponential model\r\n",
    "fitESauto = Holt(train[time_dependent_variable]).fit(optimized= True, use_brute = True)\r\n",
    "pred = fitESauto.forecast(len(test))\r\n",
    "\r\n",
    "# Different metrics for evaluating the model\r\n",
    "print(timeseries_evaluation_metrics_func(test[time_dependent_variable],pred))\r\n",
    "print(fitESauto.summary())\r\n",
    "\r\n",
    "# Creating a column for forecasts for plotting\r\n",
    "y_hat = test.copy()\r\n",
    "index = [i for i in range(len(train),len(df))]    \r\n",
    "pred = pd.Series(pred,index=index)\r\n",
    "y_hat[\"pred\"] = pred\r\n",
    "\r\n",
    "# Plotting a graph showing results\r\n",
    "plt.figure(figsize=(12,8))\r\n",
    "plt.plot(train[time_column], train[time_dependent_variable], label='Train')\r\n",
    "plt.plot(test[time_column],test[time_dependent_variable], label='Test')\r\n",
    "plt.plot(y_hat[time_column],y_hat['pred'], label='Double Exponential')\r\n",
    "plt.legend(loc='best')\r\n",
    "plt.title(\"Double Exponential Smoothing Model\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3) Triple Exponential Smoothing Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fitting and forecasting a triple exponential model. Trend and seasonality can be additive or multiplicative\r\n",
    "fitESauto = ExponentialSmoothing(train[time_dependent_variable],trend='mul',seasonal='mul',seasonal_periods=12).fit()\r\n",
    "pred = fitESauto.forecast(len(test))\r\n",
    "\r\n",
    "# Different metrics for evaluating the model\r\n",
    "print(timeseries_evaluation_metrics_func(test[time_dependent_variable],pred))\r\n",
    "print(fitESauto.summary())\r\n",
    "\r\n",
    "# Creating a column for forecasts for plotting\r\n",
    "y_hat = test.copy()\r\n",
    "index = [i for i in range(len(train),len(df))]    \r\n",
    "pred = pd.Series(pred,index=index)\r\n",
    "y_hat[\"pred\"] = pred\r\n",
    "\r\n",
    "# Plotting a graph showing results\r\n",
    "plt.figure(figsize=(12,8))\r\n",
    "plt.plot(train[time_column], train[time_dependent_variable], label='Train')\r\n",
    "plt.plot(test[time_column],test[time_dependent_variable], label='Test')\r\n",
    "plt.plot(y_hat[time_column],y_hat['pred'], label='Triple Exponential')\r\n",
    "plt.legend(loc='best')\r\n",
    "plt.title(\"Triple Exponential Smoothing Model\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4) Theta Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This model is famous because of its simplicity and success in performing the best in solving M4 forecasting challenge.\n",
    "The model is implemented in the following steps:\n",
    "\n",
    "- Test for seasonality\n",
    "- Deseasonalize if seasonality detected\n",
    "- Estimate alpha (SES) by fitting a SES model to the data and beta by OLS.\n",
    "- Forecast the series\n",
    "- Reseasonalize if the data was deseasonalized.\n",
    "\n",
    "This model uses SES and Simple OLS. For more information, https://www.statsmodels.org/stable/examples/notebooks/generated/theta-model.html  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Make sure that your time_column must be your index column, otherwise it will give an error.\r\n",
    "train.index = train[time_column]\r\n",
    "\r\n",
    "# Fitting the model\r\n",
    "fitESauto = ThetaModel(train[time_dependent_variable]).fit()\r\n",
    "pred = fitESauto.forecast(len(test),theta=np.inf)\r\n",
    "\r\n",
    "# Different metrics for evaluating the model\r\n",
    "print(timeseries_evaluation_metrics_func(test[time_dependent_variable],pred))\r\n",
    "print(fitESauto.summary())\r\n",
    "\r\n",
    "# Creating a column for forecasts for plotting\r\n",
    "y_hat = test.copy()\r\n",
    "index = [i for i in range(len(train),len(df))]    \r\n",
    "pred = pd.Series(pred,index=index)\r\n",
    "y_hat[\"pred\"] = pred\r\n",
    "\r\n",
    "# Plotting a graph showing results\r\n",
    "plt.figure(figsize=(12,8))\r\n",
    "plt.plot(train[time_column], train[time_dependent_variable], label='Train')\r\n",
    "plt.plot(test[time_column],test[time_dependent_variable], label='Test')\r\n",
    "plt.plot(y_hat[time_column],y_hat['pred'], label='Theta Model')\r\n",
    "plt.legend(loc='best')\r\n",
    "plt.title(\"Theta Model\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}